# Keystroke Dynamics Configuration File
# Zero Trust Telehealth Platform - Continuous Authentication

# Model Configuration
model:
  name: "KeystrokeDynamicsNet"
  embedding_dim: 128 # Behavioral embedding dimension
  hidden_dims: [256, 512, 256, 128]
  dropout: 0.3
  activation: "relu"
  use_batch_norm: true

# Feature Extraction
features:
  # Timing features
  hold_times: true # H.key - time key is held down
  dd_times: true # DD.key1.key2 - keydown to keydown
  ud_times: true # UD.key1.key2 - keyup to keydown

  # Statistical features
  use_statistics: true
  statistics: ["mean", "std", "median", "min", "max", "q25", "q75"]

  # Sequence features
  sequence_length: 50 # Number of keystrokes to analyze
  sliding_window: true
  window_stride: 10

  # Advanced features
  typing_speed: true
  rhythm_patterns: true
  pressure_variance: true # If available from hardware

# Training Configuration
training:
  batch_size: 64 # Increased for better gradient estimates
  epochs: 150 # More epochs for better convergence
  learning_rate: 0.0005 # Lower learning rate for fine-tuning
  weight_decay: 0.00001 # Reduced weight decay
  optimizer: "adam"
  scheduler: "cosine"
  early_stopping_patience: 40 # More patience for better convergence

  # Loss function
  loss_type: "triplet" # Use triplet loss for better embedding space
  triplet_margin: 0.2 # Smaller margin for tighter clustering
  use_hard_mining: true # Use hard negative mining for better training

  # Data split
  train_ratio: 0.6
  val_ratio: 0.2
  test_ratio: 0.2

  # Augmentation for tuplet dataset
  use_augmentation: true
  augmentation_factor: 5 # More augmentation for tuplet pairs
  noise_level: 0.02 # Very low noise for realistic augmentation
  time_warping: true
  time_warping_sigma: 0.1 # Subtle time warping
  mixup_alpha: 0.3 # Stronger mixup for same-user pairs

  # Advanced training techniques
  use_focal_loss: false # Focus on hard examples
  label_smoothing: 0.1 # Prevent overconfidence
  gradient_clipping: 1.0 # Prevent gradient explosion

# Verification Configuration
verification:
  similarity_metric: "cosine" # cosine, euclidean, or mahalanobis
  threshold: 0.85 # OPTIMAL: Best balance of accuracy (96.20%), FAR (0.39%), and FRR (7.48%)
  adaptive_threshold: false # DISABLED: Use fixed threshold instead of EER-based
  eer_target: 0.01 # Target Equal Error Rate (1% for 99% accuracy)

  # Continuous verification
  verification_window: 30 # seconds
  min_keystrokes: 20 # Minimum keystrokes for verification
  update_frequency: 5 # seconds between verifications

  # Confidence scoring
  confidence_levels:
    high: 0.90
    medium: 0.75
    low: 0.60

  # Alert thresholds
  alert_threshold: 0.60
  critical_threshold: 0.50

# Anomaly Detection
anomaly_detection:
  enabled: true
  method: "isolation_forest" # isolation_forest, one_class_svm, autoencoder
  contamination: 0.1

  # Behavioral anomalies
  detect_speed_anomalies: true
  detect_rhythm_anomalies: true
  detect_pattern_anomalies: true

  # Thresholds
  anomaly_score_threshold: 0.7
  consecutive_anomalies_alert: 3

# Enrollment Configuration
enrollment:
  min_samples: 3 # Minimum typing samples for enrollment (reduced for easier onboarding)
  max_samples: 200 # Maximum samples to store
  enrollment_sessions: 3 # Number of sessions for robust enrollment

  # Few-shot learning
  few_shot_enabled: true
  min_few_shot_samples: 3 # Reduced to match min_samples

  # Template update
  adaptive_templates: true
  template_update_rate: 0.1 # Weight for new samples

# Security Configuration
security:
  encryption_enabled: true
  tls_version: "1.3"
  store_raw_data: false # Only store embeddings, not raw keystroke data
  data_retention_days: 90

  # Privacy
  anonymize_data: true
  gdpr_compliant: true

# API Configuration
api:
  host: "0.0.0.0"
  port: 8002
  workers: 1  # Changed from 4 to 1 - Windows doesn't support multiple workers properly
  reload: false
  log_level: "info"

  # Rate limiting
  rate_limit_enabled: true
  requests_per_minute: 100

  # CORS
  cors_enabled: true
  allowed_origins: ["http://localhost:3000", "http://localhost:5000"]

# Logging Configuration
logging:
  level: "INFO"
  format: "{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}"
  rotation: "100 MB"
  retention: "30 days"
  log_dir: "logs"

# Dataset Configuration
dataset:
  use_tuplet: true # Use pre-paired tuplet dataset (RECOMMENDED for better performance)
  dsl_path: "Dataset/DSL-StrongPasswordData-Original_Dataset.xls"
  tuplet_path: "Dataset/tuplet_dataset_with_subjects1.xlsx"
  cache_dir: "cache"

# Model Paths
paths:
  model_dir: "models"
  checkpoint_dir: "models/checkpoints"
  pretrained_dir: "models/pretrained"
  embeddings_dir: "models/embeddings"
  logs_dir: "logs"
  temp_dir: "temp"

# Performance Targets (as per requirements)
performance:
  eer_threshold: 0.05 # 5% EER target
  verification_latency_ms: 500 # 500ms max latency
  throughput_requests_per_sec: 50

# Monitoring
monitoring:
  enabled: true
  metrics_port: 9002
  health_check_interval: 30
